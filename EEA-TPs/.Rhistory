rose <- data.frame(Pclass = as.factor(1),
Sex = "female",
Age = 17)
rose.prob <- predict(object = models$mod$model0, newdata = rose, type = "response")
print(paste("Probabilidad de que Rose sobreviva:", round(rose.prob,3), sep= " "))
jack <- data.frame(Pclass = as.factor(3),
Sex = "male",
Age = 20)
jack.prob <- predict(object = models$mod$model0, newdata = jack, type = "response")
print(paste("Probabilidad de que Jack sobreviva:", round(jack.prob,3), sep = " "))
models %>%
filter(grepl('1|2|3', models)) %>%
mutate(tidy = map(mod,tidy)) %>%
unnest(tidy, .drop = TRUE) %>%
mutate(estimate=round(estimate,5),
p.value=round(p.value,4))
models <- models %>%
mutate(glance = map(mod,glance))
models %>%
unnest(glance, .drop = TRUE) %>%
mutate(perc_explained_dev = 1-deviance/null.deviance) %>%
select(-c(models, df.null, AIC, BIC)) %>%
arrange(deviance)
models <- models %>%
mutate(pred= map(mod,augment, type.predict = "response"))
prediction <- models %>%
filter(grepl('2', models)) %>%
unnest(pred, .drop=TRUE)
roc_data <- roc(response=prediction$Survived, predictor=prediction$.fitted)
ggroc(roc_data, size=1, color="turquoise3") +
geom_abline(slope = 1, intercept = 1, linetype='dashed') +
theme_bw() +
labs(title='Curva ROC',
subtitle = 'Modelo2: Survived ~ Pclass + Fare + Sex + Age')
print(paste('AUC: Modelo2: Survived~Pclass+Embarked+Sex+Age:', roc_data$auc))
ggplot(prediction, aes(x=Survived, y=.fitted, group=Survived,fill=factor(Survived))) +
geom_violin() +
theme_bw() +
guides(fill=FALSE) +
scale_x_discrete("Supervivencia", breaks = c("0","1"),
labels=c("No sobrevivientes","Sobrevivientes")) +
labs(title='Violin plot',
subtitle = 'Modelo2: Survived ~ Pclass + Fare + Sex + Age',
y='Probabilidad predicha')
# se testean el modelo con los datos de VALIDACIÓN reservados
valid <- models %>%
filter(grepl('2',models)) %>%
mutate(val= map(mod,augment, newdata=validationset, type.predict = "response"))
valid.results <-  valid %>%
unnest(val, .drop=TRUE)
valid.results
# función que calcula las métricas de las predicciones de acuerdo a los puntos de corte establecidos
prediction_metrics <- function(cutoff, predictions=valid.results){
table <- predictions %>%
mutate(predicted_class=if_else(.fitted>cutoff, 1, 0) %>% as.factor(),
Survived= factor(Survived))
confusionMatrix(table(table$predicted_class, table$Survived), positive = "1") %>%
tidy() %>%
select(term, estimate) %>%
filter(term %in% c('accuracy', 'sensitivity', 'specificity', 'precision','recall')) %>%
mutate(cutoff=cutoff)
}
# se definen puntos de corte
cutoffs = seq(0.05,0.95,0.01)
logit_pred= map_dfr(cutoffs, prediction_metrics) %>% mutate(term=as.factor(term))
# se seleccionan los puntos de corte con mayor accuracy
cutoff.max_ac <- logit_pred %>%
filter(term=='accuracy') %>%
filter(estimate == max(estimate)) %>%
select(cutoff)
ggplot(logit_pred, aes(cutoff,estimate, group=term, color=term)) + geom_line(size=1) +
theme_bw() +
labs(title= 'Accuracy, Sensitivity, Specificity, Recall y Precision', subtitle= 'Model2 - Sobre conjunto de validación', color="") +
geom_vline(xintercept = min(cutoff.max_ac), linetype="dotted",  color = "black", size=1) +
geom_vline(xintercept = max(cutoff.max_ac), linetype="dotted",  color = "black", size=1)
# se establece el punto de corte
sel_cutoff = max(cutoff.max_ac)
table <- valid.results %>%
mutate(predicted_class=if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(),
Survived = factor(Survived))
# se crea la matriz de confusión
confusionMatrix(table(table$Survived, table$predicted_class), positive = "1")
# se carga el conjunto de testeo
testset <- fread("titanic_complete_test.csv")
# se convierten las variables a factores
testset <- testset %>%
select(PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>%
mutate(Survived = as_factor(Survived),
Pclass = as_factor(Pclass),
Embarked = as_factor(Embarked))
glimpse(testset)
# se calcula el porcentaje de sobrevivientes en el conjunto de testeo
surv.testset <- nrow(testset[testset$Survived==1,])
dist.testset <- round((surv.testset/nrow(testset))*100,0)
print(paste("Porcentaje de sobrevivientes en el conjunto de testeo:", dist.testset,"%"))
# se entrena el modelo 2 con TODOS los datos para ENTRENAMIENTO
model2test <- glm(logit_formulae$model2, family = 'binomial', data = dataset)
# se calculan las predicciones para el conjunto de TESTEO
test.table = augment(x=model2test, newdata=testset, type.predict='response')
# se realiza la clasificación en clases según el punto de corte elegido
test.table = test.table %>%
mutate(predicted_class=if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(),
Survived= factor(Survived))
test.table
# se crea la matriz de confusión
confusionMatrix(table(test.table$Survived, test.table$predicted_class), positive = "1")
# se cargan las librerías a utilizar
library("tidyverse")
library("data.table")
library("ggplot2")
library("GGally")
library("modelr")
library("gridExtra")
library("caret")
library("broom")
library("pROC")
# se elige una semilla
set.seed(1912)
# se carga el dataset
dataset <- fread("titanic_complete_train.csv")
glimpse(dataset)
# se seleccinan las variables deseadas y se convierten algunas a factores
dataset <- dataset %>%
select(PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>%
mutate(Survived = as_factor(Survived),
Pclass = as_factor(Pclass),
Embarked = as_factor(Embarked))
dataset
variables <- c('Survived','Pclass','Sex','Age','Fare')
ggpairs(dataset[variables],
mapping = aes(colour= Survived)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) + theme_bw()
# cantidad de sobrevivientes según clase
dataset %>%
select(Pclass, Survived) %>%
group_by(Pclass) %>%
count(Survived)
# cantidad de sobrevivientes según sexo
dataset %>%
select(Sex, Survived) %>%
group_by(Sex) %>%
count(Survived)
ggplot(dataset,
aes(x=Survived, fill=Survived)) +
geom_bar() +
geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 50)) +
labs(title = "Supervivencia - Distribución de clases",
y = "Frecuencia absoluta") +
scale_x_discrete("Supervivencia", breaks = c("0","1"),
labels=c("No sobrevivientes","Sobrevivientes")) +
theme(legend.position = "none")
# porcentaje de sobrevivientes
dist.dataset <- round((342 / nrow(dataset)) * 100,0)
print(paste("Porcentaje de sobrevivientes en el dataset:", dist.dataset,"%"))
# se particiona el dataset en entrenamiento y validación
train_valid <- dataset %>% resample_partition(c(train=0.7,valid=0.3))
trainset <- train_valid$train %>% as_tibble()
validationset <- train_valid$valid %>% as_tibble()
# se grafican las distribuciones de clases de ambos conjuntos
trainplot <- ggplot(trainset,
aes(x=Survived, fill=Survived)) +
geom_bar() +
geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 50)) +
labs(title = "Conjunto de entrenamiento",
y = "Frecuencia absoluta") +
scale_x_discrete("Sobrevivientes", breaks = c("0","1"),
labels=c("No sobrevivientes","Sobrevivientes")) +
theme(legend.position = "none")
validplot <- ggplot(validationset,
aes(x=Survived, fill=Survived)) +
geom_bar() +
geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 22)) +
labs(title = "Conjunto de validación",
y = "Frecuencia absoluta") +
scale_x_discrete("Sobrevivientes", breaks = c("0","1"),
labels=c("No sobrevivientes","Sobrevivientes")) +
theme(legend.position = "none")
grid.arrange(
trainplot,
validplot,
nrow = 1,
top = "Sobrevivientes - Distribución de clases"
)
# porcentaje de sobrevivientes en set de entrenamiento
dist.train <- round((240 / nrow(trainset)) * 100,0)
print(paste("Porcentaje de sobrevivientes en el conjunto de entrenamiento:", dist.train,"%"))
# porcentaje de sobrevivientes en set de validación
dist.val <- round((102 / nrow(validationset)) * 100,0)
print(paste("Proporción de sobrevivientes en el conjunto de validación:", dist.val,"%"))
# se definen las fórmulas para los 4 modelos
logit_formulae <- formulas(.response = ~Survived,
model0 = ~ Pclass + Sex + Age,
model1 = ~ Fare + Sex,
model2 = ~ Pclass + Sex + Age + Fare,
model3 = ~ Sex + Parch
)
# se genera un data frame con la información y los modelos ajustados
models <- data_frame(logit_formulae) %>%
mutate(models = names(logit_formulae),
expression = paste(logit_formulae),
mod = map(logit_formulae, ~glm(.,family = 'binomial', data = trainset)))
models
summary(models$mod$model0)
rose <- data.frame(Pclass = as.factor(1),
Sex = "female",
Age = 17)
rose.prob <- predict(object = models$mod$model0, newdata = rose, type = "response")
print(paste("Probabilidad de que Rose sobreviva:", round(rose.prob,3), sep= " "))
jack <- data.frame(Pclass = as.factor(3),
Sex = "male",
Age = 20)
jack.prob <- predict(object = models$mod$model0, newdata = jack, type = "response")
print(paste("Probabilidad de que Jack sobreviva:", round(jack.prob,3), sep = " "))
models %>%
filter(grepl('1|2|3', models)) %>%
mutate(tidy = map(mod,tidy)) %>%
unnest(tidy, .drop = TRUE) %>%
mutate(estimate=round(estimate,5),
p.value=round(p.value,4))
models <- models %>%
mutate(glance = map(mod,glance))
models %>%
unnest(glance, .drop = TRUE) %>%
mutate(perc_explained_dev = 1-deviance/null.deviance) %>%
select(-c(models, df.null, AIC, BIC)) %>%
arrange(deviance)
models <- models %>%
mutate(pred= map(mod,augment, type.predict = "response"))
prediction <- models %>%
filter(grepl('2', models)) %>%
unnest(pred, .drop=TRUE)
roc_data <- roc(response=prediction$Survived, predictor=prediction$.fitted)
ggroc(roc_data, size=1, color="turquoise3") +
geom_abline(slope = 1, intercept = 1, linetype='dashed') +
theme_bw() +
labs(title='Curva ROC',
subtitle = 'Modelo2: Survived ~ Pclass + Fare + Sex + Age')
print(paste('AUC: Modelo2: Survived~Pclass+Embarked+Sex+Age:', roc_data$auc))
ggplot(prediction, aes(x=Survived, y=.fitted, group=Survived,fill=factor(Survived))) +
geom_violin() +
theme_bw() +
guides(fill=FALSE) +
scale_x_discrete("Supervivencia", breaks = c("0","1"),
labels=c("No sobrevivientes","Sobrevivientes")) +
labs(title='Violin plot',
subtitle = 'Modelo2: Survived ~ Pclass + Fare + Sex + Age',
y='Probabilidad predicha')
# se testean el modelo con los datos de VALIDACIÓN reservados
valid <- models %>%
filter(grepl('2',models)) %>%
mutate(val= map(mod,augment, newdata=validationset, type.predict = "response"))
valid.results <-  valid %>%
unnest(val, .drop=TRUE)
valid.results
# función que calcula las métricas de las predicciones de acuerdo a los puntos de corte establecidos
prediction_metrics <- function(cutoff, predictions=valid.results){
table <- predictions %>%
mutate(predicted_class=if_else(.fitted>cutoff, 1, 0) %>% as.factor(),
Survived= factor(Survived))
confusionMatrix(table(table$predicted_class, table$Survived), positive = "1") %>%
tidy() %>%
select(term, estimate) %>%
filter(term %in% c('accuracy', 'sensitivity', 'specificity', 'precision','recall')) %>%
mutate(cutoff=cutoff)
}
# se definen puntos de corte
cutoffs = seq(0.05,0.95,0.01)
logit_pred= map_dfr(cutoffs, prediction_metrics) %>% mutate(term=as.factor(term))
# se seleccionan los puntos de corte con mayor accuracy
cutoff.max_ac <- logit_pred %>%
filter(term=='accuracy') %>%
filter(estimate == max(estimate)) %>%
select(cutoff)
ggplot(logit_pred, aes(cutoff,estimate, group=term, color=term)) + geom_line(size=1) +
theme_bw() +
labs(title= 'Accuracy, Sensitivity, Specificity, Recall y Precision', subtitle= 'Model2 - Sobre conjunto de validación', color="") +
geom_vline(xintercept = min(cutoff.max_ac), linetype="dotted",  color = "black", size=1) +
geom_vline(xintercept = max(cutoff.max_ac), linetype="dotted",  color = "black", size=1)
# se establece el punto de corte
sel_cutoff = max(cutoff.max_ac)
table <- valid.results %>%
mutate(predicted_class=if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(),
Survived = factor(Survived))
# se crea la matriz de confusión
confusionMatrix(table(table$Survived, table$predicted_class), positive = "1")
# se carga el conjunto de testeo
testset <- fread("titanic_complete_test.csv")
# se convierten las variables a factores
testset <- testset %>%
select(PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>%
mutate(Survived = as_factor(Survived),
Pclass = as_factor(Pclass),
Embarked = as_factor(Embarked))
glimpse(testset)
# se calcula el porcentaje de sobrevivientes en el conjunto de testeo
surv.testset <- nrow(testset[testset$Survived==1,])
dist.testset <- round((surv.testset/nrow(testset))*100,0)
print(paste("Porcentaje de sobrevivientes en el conjunto de testeo:", dist.testset,"%"))
# se entrena el modelo 2 con TODOS los datos para ENTRENAMIENTO
model2test <- glm(logit_formulae$model2, family = 'binomial', data = dataset)
# se calculan las predicciones para el conjunto de TESTEO
test.table = augment(x=model2test, newdata=testset, type.predict='response')
# se realiza la clasificación en clases según el punto de corte elegido
test.table = test.table %>%
mutate(predicted_class=if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(),
Survived= factor(Survived))
test.table
# se crea la matriz de confusión
confusionMatrix(table(test.table$Survived, test.table$predicted_class), positive = "1")
# se cargan las librerías a utilizar
library("tidyverse")
library("data.table")
library("ggplot2")
library("GGally")
library("modelr")
library("gridExtra")
library("caret")
library("broom")
library("pROC")
# se elige una semilla
set.seed(1912)
# se carga el dataset
dataset <- fread("titanic_complete_train.csv")
glimpse(dataset)
# se seleccinan las variables deseadas y se convierten algunas a factores
dataset <- dataset %>%
select(PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>%
mutate(Survived = as_factor(Survived),
Pclass = as_factor(Pclass),
Embarked = as_factor(Embarked))
dataset
variables <- c('Survived','Pclass','Sex','Age','Fare')
ggpairs(dataset[variables],
mapping = aes(colour= Survived)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) + theme_bw()
# cantidad de sobrevivientes según clase
dataset %>%
select(Pclass, Survived) %>%
group_by(Pclass) %>%
count(Survived)
# cantidad de sobrevivientes según sexo
dataset %>%
select(Sex, Survived) %>%
group_by(Sex) %>%
count(Survived)
ggplot(dataset,
aes(x=Survived, fill=Survived)) +
geom_bar() +
geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 50)) +
labs(title = "Supervivencia - Distribución de clases",
y = "Frecuencia absoluta") +
scale_x_discrete("Supervivencia", breaks = c("0","1"),
labels=c("No sobrevivientes","Sobrevivientes")) +
theme(legend.position = "none")
# porcentaje de sobrevivientes
dist.dataset <- round((342 / nrow(dataset)) * 100,0)
print(paste("Porcentaje de sobrevivientes en el dataset:", dist.dataset,"%"))
# se particiona el dataset en entrenamiento y validación
train_valid <- dataset %>% resample_partition(c(train=0.7,valid=0.3))
trainset <- train_valid$train %>% as_tibble()
validationset <- train_valid$valid %>% as_tibble()
# se grafican las distribuciones de clases de ambos conjuntos
trainplot <- ggplot(trainset,
aes(x=Survived, fill=Survived)) +
geom_bar() +
geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 50)) +
labs(title = "Conjunto de entrenamiento",
y = "Frecuencia absoluta") +
scale_x_discrete("Sobrevivientes", breaks = c("0","1"),
labels=c("No sobrevivientes","Sobrevivientes")) +
theme(legend.position = "none")
validplot <- ggplot(validationset,
aes(x=Survived, fill=Survived)) +
geom_bar() +
geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 22)) +
labs(title = "Conjunto de validación",
y = "Frecuencia absoluta") +
scale_x_discrete("Sobrevivientes", breaks = c("0","1"),
labels=c("No sobrevivientes","Sobrevivientes")) +
theme(legend.position = "none")
grid.arrange(
trainplot,
validplot,
nrow = 1,
top = "Sobrevivientes - Distribución de clases"
)
# porcentaje de sobrevivientes en set de entrenamiento
dist.train <- round((240 / nrow(trainset)) * 100,0)
print(paste("Porcentaje de sobrevivientes en el conjunto de entrenamiento:", dist.train,"%"))
# porcentaje de sobrevivientes en set de validación
dist.val <- round((102 / nrow(validationset)) * 100,0)
print(paste("Proporción de sobrevivientes en el conjunto de validación:", dist.val,"%"))
# se definen las fórmulas para los 4 modelos
logit_formulae <- formulas(.response = ~Survived,
model0 = ~ Pclass + Sex + Age,
model1 = ~ Fare + Sex,
model2 = ~ Pclass + Sex + Age + Fare,
model3 = ~ Sex + Parch
)
# se genera un data frame con la información y los modelos ajustados
models <- data_frame(logit_formulae) %>%
mutate(models = names(logit_formulae),
expression = paste(logit_formulae),
mod = map(logit_formulae, ~glm(.,family = 'binomial', data = trainset)))
models
summary(models$mod$model0)
rose <- data.frame(Pclass = as.factor(1),
Sex = "female",
Age = 17)
rose.prob <- predict(object = models$mod$model0, newdata = rose, type = "response")
print(paste("Probabilidad de que Rose sobreviva:", round(rose.prob,3), sep= " "))
jack <- data.frame(Pclass = as.factor(3),
Sex = "male",
Age = 20)
jack.prob <- predict(object = models$mod$model0, newdata = jack, type = "response")
print(paste("Probabilidad de que Jack sobreviva:", round(jack.prob,3), sep = " "))
models %>%
filter(grepl('1|2|3', models)) %>%
mutate(tidy = map(mod,tidy)) %>%
unnest(tidy, .drop = TRUE) %>%
mutate(estimate=round(estimate,5),
p.value=round(p.value,4))
models <- models %>%
mutate(glance = map(mod,glance))
models %>%
unnest(glance, .drop = TRUE) %>%
mutate(perc_explained_dev = 1-deviance/null.deviance) %>%
select(-c(models, df.null, AIC, BIC)) %>%
arrange(deviance)
models <- models %>%
mutate(pred= map(mod,augment, type.predict = "response"))
prediction <- models %>%
filter(grepl('2', models)) %>%
unnest(pred, .drop=TRUE)
roc_data <- roc(response=prediction$Survived, predictor=prediction$.fitted)
ggroc(roc_data, size=1, color="turquoise3") +
geom_abline(slope = 1, intercept = 1, linetype='dashed') +
theme_bw() +
labs(title='Curva ROC',
subtitle = 'Modelo2: Survived ~ Pclass + Fare + Sex + Age')
print(paste('AUC: Modelo2: Survived~Pclass+Embarked+Sex+Age:', roc_data$auc))
ggplot(prediction, aes(x=Survived, y=.fitted, group=Survived,fill=factor(Survived))) +
geom_violin() +
theme_bw() +
guides(fill=FALSE) +
scale_x_discrete("Supervivencia", breaks = c("0","1"),
labels=c("No sobrevivientes","Sobrevivientes")) +
labs(title='Violin plot',
subtitle = 'Modelo2: Survived ~ Pclass + Fare + Sex + Age',
y='Probabilidad predicha')
# se testean el modelo con los datos de VALIDACIÓN reservados
valid <- models %>%
filter(grepl('2',models)) %>%
mutate(val= map(mod,augment, newdata=validationset, type.predict = "response"))
valid.results <-  valid %>%
unnest(val, .drop=TRUE)
valid.results
# función que calcula las métricas de las predicciones de acuerdo a los puntos de corte establecidos
prediction_metrics <- function(cutoff, predictions=valid.results){
table <- predictions %>%
mutate(predicted_class=if_else(.fitted>cutoff, 1, 0) %>% as.factor(),
Survived= factor(Survived))
confusionMatrix(table(table$predicted_class, table$Survived), positive = "1") %>%
tidy() %>%
select(term, estimate) %>%
filter(term %in% c('accuracy', 'sensitivity', 'specificity', 'precision','recall')) %>%
mutate(cutoff=cutoff)
}
# se definen puntos de corte
cutoffs = seq(0.05,0.95,0.01)
logit_pred= map_dfr(cutoffs, prediction_metrics) %>% mutate(term=as.factor(term))
# se seleccionan los puntos de corte con mayor accuracy
cutoff.max_ac <- logit_pred %>%
filter(term=='accuracy') %>%
filter(estimate == max(estimate)) %>%
select(cutoff)
ggplot(logit_pred, aes(cutoff,estimate, group=term, color=term)) + geom_line(size=1) +
theme_bw() +
labs(title= 'Accuracy, Sensitivity, Specificity, Recall y Precision', subtitle= 'Model2 - Sobre conjunto de validación', color="") +
geom_vline(xintercept = min(cutoff.max_ac), linetype="dotted",  color = "black", size=1) +
geom_vline(xintercept = max(cutoff.max_ac), linetype="dotted",  color = "black", size=1)
# se establece el punto de corte
sel_cutoff = max(cutoff.max_ac)
table <- valid.results %>%
mutate(predicted_class=if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(),
Survived = factor(Survived))
# se crea la matriz de confusión
confusionMatrix(table(table$Survived, table$predicted_class), positive = "1")
# se carga el conjunto de testeo
testset <- fread("titanic_complete_test.csv")
# se convierten las variables a factores
testset <- testset %>%
select(PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>%
mutate(Survived = as_factor(Survived),
Pclass = as_factor(Pclass),
Embarked = as_factor(Embarked))
glimpse(testset)
# se calcula el porcentaje de sobrevivientes en el conjunto de testeo
surv.testset <- nrow(testset[testset$Survived==1,])
dist.testset <- round((surv.testset/nrow(testset))*100,0)
print(paste("Porcentaje de sobrevivientes en el conjunto de testeo:", dist.testset,"%"))
# se entrena el modelo 2 con TODOS los datos para ENTRENAMIENTO
model2test <- glm(logit_formulae$model2, family = 'binomial', data = dataset)
# se calculan las predicciones para el conjunto de TESTEO
test.table = augment(x=model2test, newdata=testset, type.predict='response')
# se realiza la clasificación en clases según el punto de corte elegido
test.table = test.table %>%
mutate(predicted_class=if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(),
Survived= factor(Survived))
test.table
# se crea la matriz de confusión
confusionMatrix(table(test.table$Survived, test.table$predicted_class), positive = "1")
