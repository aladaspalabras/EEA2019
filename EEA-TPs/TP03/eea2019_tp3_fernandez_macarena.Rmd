---
title: "Trabajo Práctico N°3"
author: "Macarena Fernandez Urquiza"
output: 
  html_notebook: 
    toc: true
    toc_float: true
    depth: 3
    includes:
      before_body: header.html
      after_body: footer.html
---
</style>
<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
body {
text-align: justify}
h1{
  font-size: 19pt;
  margin-top: 70px;
}
h2{
  font-size: 17pt;
}
h3{
  font-size: 15pt
}
</style>

# 1. Objetivos del trabajo

TO-DO

```{r, message=FALSE, warning=FALSE}
# Se cargan las librerías a utilizar
library("tidyverse")
library("data.table")
library("ggplot2")
library("GGally")
library("modelr")
library("gridExtra")
library("caret")
library("broom")
library("pROC")
# Se elige una semilla
set.seed(1912)
```

# 2. Preparación de los datos

```{r}
dataset <- fread("titanic_complete_train.csv")

glimpse(dataset)
```

En primer lugar, se carga el daaset. Este cuenta con 891 registros y 12 variables:

 - PassengerId: Id único por pasajero
 - Survived: sobreviviente (1) o fallecido (0)
 - Pclass: clase en la que viajaba (1ra, 2da o 3ra)
 - Name: nombre del pasajero
 - Sex: sexo del pasajero
 - Age: edad del pasajero
 - SibSp: cantidad de hermanos y/o cónyuge a bordo
 - Parch: cantidad de padres/hijos a bordo
 - Ticket: número de ticket
 - Fare: tarifa pagada por el ticket
 - Cabin: número de cabina
 - Embarked: lugar de abordo (C: Cherbourg, S: Southampton, Q: Queenstown)
 
De éstas, nos quedaremos con _PassengerId_, _Sex_, _Age_, _SibSp_, _Parch_, _Fare_, _Pclass_, _Survived_ y _Embarked_, que son las que utilizaremos para el ajuste de los distintos modelos, y convertimos las últimas tres a factores.

El nuevo dataset consta de 891 registros y 9 variables.

```{r}
dataset <- dataset %>% 
  select(PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>% 
  mutate(Survived = as_factor(Survived),
         Pclass = as_factor(Pclass),
         Embarked = as_factor(Embarked))

dataset
```

Con el objetivo de visualizar la relación entre distintas variables, se realiza un gráfico de ggpairs de los atributos _Survived_, _Pclass_, _Sex_, _Age_ y _Fare_.

En primer lugar, se observa que la variable _Sobreviviente_ contiene clases desbalanceadas: la cantidad de fallecidos supera a la de sobrevivientes.

Además, al relacionar esta variable con la _clase en la cual viajaban los pasajeros_, vemos tres agrupaciones. En la primera, posiblemente correspondiente a la primera clase, hay mayor cantidad de sobrevivientes que de fallecidos; en la segunda clase, ambas cantidades parecen ser similares, y en la tercera, la relación se presenta a la inversa: hay más fallecidos que sobrevivientes.

Asimismo, al vincular la supervivencia con el _sexo_ de los pasajeros se evidencian dos comportamientos diferenciados: en las mujeres hay más sobrevivientes que fallecidos, y en los hombres ocurre lo contrario.

Si también relacionamos esta información con la que aporta la variable de la _edad_, vemos que la media de las personas a bordo del Titanic se encontraba entre los 20 y 30 años, y que también aquí se encuentra la media de los fallecidos, en su mayoría, varones de la tercera clase.

Apoyamos estas primeras aproximaciones a los datos con tablas que nos permiten confirmar nuestras hipotesis.

```{r, message=FALSE, warning=FALSE}
variables <- c('Survived','Pclass','Sex','Age','Fare')

ggpairs(dataset[, variables, with=FALSE],
        mapping = aes(colour= Survived)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + theme_bw()
```


```{r}
# cantidad de sobrevivientes según clase
dataset %>%
  select(Pclass, Survived) %>% 
  group_by(Survived) %>%
  count()

# cantidad de sobrevivientes según sexo
dataset %>%
  select(Sex, Survived) %>% 
  group_by(Survived) %>%
  count()
```

También graficamos la distribución de la variable _Sobreviviente_, en la cual se observan 342 sobrevivientes. Esto representa un 38% del total de registros.

```{r}
ggplot(dataset, 
       aes(x=Survived, fill=Survived)) + 
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 50)) +
  labs(title = "Supervivencia - Distribución de clases",
       y = "Frecuencia absoluta") +
  scale_x_discrete("Supervivencia", breaks = c("0","1"),
                   labels=c("No sobrevivientes","Sobrevivientes")) +
  theme(legend.position = "none")

```

```{r}
# porcentaje de sobrevivientes
round((342 / nrow(dataset)) * 100,0)
```

Con el objetivo de poder entrenar un modelo y validarlo previamente a realizar nuestras predicciones, dividimos el dataset en un conjunto de entrenamiento (70% de los datos) y validación (30%). Para ello usamos la función *resample_partition* de **modelr**.

Constatamos también que ambos conjuntos presentan aproximadamente la misma distribución en la variable _Sobreviviente_ que la que mostró el dataset completo, dado que esta será nuestra clase target y queremos asegurarnos de entrenar y validar con conjuntos de datos semejantes. 

```{r}
train_valid <- dataset %>% resample_partition(c(train=0.7,valid=0.3))

trainset <- train_valid$train %>% as_tibble()
validationset <- train_valid$valid %>% as_tibble()

trainplot <- ggplot(trainset, 
       aes(x=Survived, fill=Survived)) + 
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 50)) +
  labs(title = "Conjunto de entrenamiento",
       y = "Frecuencia absoluta") +
  scale_x_discrete("Sobrevivientes", breaks = c("0","1"),
                   labels=c("No sobrevivientes","Sobrevivientes")) +
  theme(legend.position = "none")

validplot <- ggplot(validationset, 
       aes(x=Survived, fill=Survived)) + 
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 22)) +
  labs(title = "Conjunto de validación",
       y = "Frecuencia absoluta") +
  scale_x_discrete("Sobrevivientes", breaks = c("0","1"),
                   labels=c("No sobrevivientes","Sobrevivientes")) +
  theme(legend.position = "none")

grid.arrange(
  trainplot,
  validplot,
  nrow = 1,
  top = "Sobrevivientes - Distribución de clases"
)
```

```{r}
# porcentaje de sobrevivientes en set de entrenamiento
round((240 / nrow(trainset)) * 100,0)

# porcentaje de sobrevivientes en set de validación
round((102 / nrow(validationset)) * 100,0)
```

# 3. Generación de modelos

Procedemos a ajustar 4 modelos de regresión logísitca utilizando el conjunto de entrenamiento:

- **modelo 0:** predice la probabilidad de sobrevivir en función de la clase, el sexo y la edad
- **modelo 1:** predice la probabilidad de sobrevivir en función de la clase y el sexo
- **modelo 2:** predice la probabilidad de sobrevivir en función de la clase, el sexo, la edad y el lugar de abordaje
- **modelo 3:** predice la probabilidad de sobrevivir en función del sexo y el lugar de abordaje

```{r}
logit_formulae <- formulas(.response = ~Survived,
                           model0 = ~ Pclass + Sex + Age,
                           model1 = ~ Pclass + Sex, 
                           model2 = ~ Pclass + Sex + Age + Embarked,
                           model3 = ~ Sex + Embarked
                         )

models <- data_frame(logit_formulae) %>% 
  mutate(models = names(logit_formulae), 
         expression = paste(logit_formulae), 
         mod = map(logit_formulae, ~glm(.,family = 'binomial', data = trainset))) 

models
```

Nos detenemos a analizar los coeficientes del primer modelo ajustado, el modelo 0.

TO-DO Dar una breve interpretación de los coeficientes y su significatividad

```{r}
summary(models$mod$model0)
```

¿Quién tiene una mayor probabilidad de supervivencia? Rose que es una mujer de 17 años que viaja en primera clase o Jack que es un hombre de 20 años viajando en tercera clase

```{r}
rose <- data.frame(Pclass = as.factor(1), 
                   Sex = "female",
                   Age = 17)

rose.prob <- predict(object = glm.fit, newdata = rose, type = "response")

print(paste("Probabilidad de que Rose sobreviva:", round(rose.prob,3), sep= " "))

jack <- data.frame(Pclass = as.factor(3),
                   Sex = "male",
                   Age = 20)

jack.prob <- predict(object = glm.fit, newdata = jack, type = "response")

print(paste("Probabilidad de que Jack sobreviva:", round(jack.prob,3), sep = " "))
```

## 3.1. Generar 3 modelos de regresión logística sobre el dataset de entrenamiento utilizando diferentes combinaciones de variables. Al menos dos modelos deben ser multivariados

```{r}
logit_formulae <- formulas(.response = ~Survived,
                           model0 = ~ Pclass + Sex + Age,
                           model1 = ~ Pclass + Sex, 
                           model2 = ~ Pclass + Embarked + Sex + Age,
                           model3 = ~ Embarked + Sex
                         )

models <- data_frame(logit_formulae) %>% 
  mutate(models = names(logit_formulae), 
         expression = paste(logit_formulae), 
         mod = map(logit_formulae, ~glm(.,family = 'binomial', data = trainset))) 

models
```


```{r}
models %>% 
  filter(grepl('1|2|3', models)) %>% 
  mutate(tidy = map(mod,tidy)) %>%  
  unnest(tidy, .drop = TRUE) %>% 
  mutate(estimate=round(estimate,5),
         p.value=round(p.value,4))
```

TO-DO: analizar modelos

## 3.2. Ordenar por la deviance los 3 modelos creados en el punto 3)a) y el creado en el punto 2)a) y seleccionar el mejor modelo en términos de la deviance explicada

```{r}
models <- models %>% 
  mutate(glance = map(mod,glance))

models %>% 
  unnest(glance, .drop = TRUE) %>%
  mutate(perc_explained_dev = 1-(deviance/null.deviance)) %>% 
  select(-c(models, df.null, AIC, BIC)) %>% 
  arrange(deviance)
```

Mejor modelo: modelo2

# 4. Evaluación del modelo

## 4.1. Realizar el gráfico de curva ROC y obtener el AUC para el modelo elegido. Interpretar el gráfico

```{r}
models <- models %>% 
  mutate(pred= map(mod,augment, type.predict = "response"))

prediction <- models %>% 
  filter(grepl('2', models)) %>% 
  unnest(pred, .drop=TRUE)
 
roc_data <- roc(response=prediction$Survived, predictor=prediction$.fitted)

ggroc(roc_data, size=1, color="turquoise3") + 
  geom_abline(slope = 1, intercept = 1, linetype='dashed') +
  theme_bw() + 
  labs(title='Curva ROC', 
       subtitle = 'Modelo2: Survived ~ Pclass + Embarked + Sex + Age')

```

```{r}
print(paste('AUC: Modelo2: Survived~Pclass+Embarked+Sex+Age:', roc_data$auc))
```

## 4.2. Realizar un violin plot e interpretar

```{r}
ggplot(prediction, aes(x=Survived, y=.fitted, group=Survived,fill=factor(Survived))) + 
  geom_violin() +
  theme_bw() +
  guides(fill=FALSE) +
  scale_x_discrete("Supervivencia", breaks = c("0","1"),
                   labels=c("No sobrevivientes","Sobrevivientes")) +
  labs(title='Violin plot', 
       subtitle = 'Modelo2: Survived ~ Pclass + Embarked + Sex + Age', 
       y='Probabilidad predicha')
```


# 5. Elección del punto de corte

## 5.1. Sobre el dataset de validación realizar un gráfico de Accuracy, Specificity, Recall y Precision en función del punto de corte


```{r}
valid <- models %>% 
  filter(grepl('2',models)) %>% 
  mutate(val= map(mod,augment, newdata=validationset, type.predict = "response"))

valid.results <-  valid %>%
  unnest(val, .drop=TRUE)

valid.results
```


```{r}
prediction_metrics <- function(cutoff, predictions=valid.results){
  table <- predictions %>% 
    mutate(predicted_class=if_else(.fitted>cutoff, 1, 0) %>% as.factor(),
           Survived= factor(Survived))
  confusionMatrix(table(table$predicted_class, table$Survived), positive = "1") %>%
    tidy() %>%
    select(term, estimate) %>%
    filter(term %in% c('accuracy', 'sensitivity', 'specificity', 'precision','recall')) %>%
    mutate(cutoff=cutoff)
}

cutoffs = seq(0.05,0.95,0.01)
logit_pred= map_dfr(cutoffs, prediction_metrics) %>% mutate(term=as.factor(term))

ggplot(logit_pred, aes(cutoff,estimate, group=term, color=term)) + geom_line(size=1) +
  theme_bw() +
  labs(title= 'Accuracy, Sensitivity, Specificity, Recall y Precision', subtitle= 'Model2 - Sobre conjunto de validación', color="")
```


## 5.2. Elegir un punto de corte y explicar su decisión

0.4

## 5.3. Obtener la matriz de confusión con el modelo y punto de corte elegidos. Interpretarla

```{r}
sel_cutoff = 0.4

table <- valid.results %>% 
  mutate(predicted_class=if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(), 
         Survived = factor(Survived))

# Creamos la matriz de confusión
confusionMatrix(table(table$Survived, table$predicted_class), positive = "1")
```

# 6. Dataset de testeo

## 6.1. Leer el archivo titanic_complete_test.csv y transformar las variables Survived, Pclass y Embarked a factor

```{r}
testset <- fread("titanic_complete_test.csv")

testset <- testset %>% 
  select(PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>% 
  mutate(Survived = as_factor(Survived),
         Pclass = as_factor(Pclass),
         Embarked = as_factor(Embarked))

glimpse(testset)
```

## 6.2. Con el modelo y punto de corte elegidos clasificar a las personas del dataset de testing.

```{r}
sel_cutoff = 0.4

model2test <- glm(logit_formulae$model2, family = 'binomial', data = dataset)

# Agregamos la predicciones al dataset de testeo
test.table = augment(x=model2test, newdata=testset, type.predict='response') 

# Clasificamos utilizamos el punto de corte
test.table = test.table %>% 
  mutate(predicted_class=if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(),
         Survived= factor(Survived))
```

## 6.3. Obtener la matriz de confusión y comparar con la obtenida en el punto 5)c).

```{r}
# Creamos la matriz de confusión
confusionMatrix(table(test.table$Survived, test.table$predicted_class), positive = "1")
```

# 7. Conclusiones
