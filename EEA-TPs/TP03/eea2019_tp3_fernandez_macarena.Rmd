---
title: "Trabajo Práctico N°3"
author: "Macarena Fernandez Urquiza"
output: 
  html_notebook: 
    toc: true
    toc_float: true
    depth: 3
    includes:
      before_body: header.html
      after_body: footer.html
---
</style>
<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
body {
text-align: justify}
h1{
  font-size: 19pt;
  margin-top: 70px;
}
h2{
  font-size: 17pt;
}
h3{
  font-size: 15pt
}
</style>

Se cargan las librerías que se utilizarán a lo largo del trabajo.

```{r, message=FALSE, warning=FALSE}
library("tidyverse")
library("data.table")
library("ggplot2")
library("GGally")
library("modelr")
library("gridExtra")
library("caret")
library("broom")
library("pROC")
```

# 1. Preparación de los datos

## 1.1. Leer el archivo titanic_complete_train.csv y mostrar su estructura

Se cargan los datos y se lee su estructura.

```{r}
dataset <- fread("titanic_complete_train.csv")

dataset
```

```{r}
glimpse(dataset)
```

## 1.2. Seleccionar las variables PassengerId, Survived, Pclass, Sex, Age, SibSp,Parch, Fare y Embarked

```{r}
dataset.filtrado <- dataset %>% 
  select(PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked)

dataset.filtrado
```

## 1.3. Transformar las variables Survived, Pclass y Embarked a factor

```{r}
dataset.preproc <- dataset.filtrado %>% 
  mutate(Survived = as_factor(Survived),
         Pclass = as_factor(Pclass),
         Embarked = as_factor(Embarked))

dataset.preproc
```

```{r}
glimpse(dataset.preproc)
```

## 1.4. Realizar un gráfico de ggpairs para las variables Survived, Pclass, Sex, Age y Fare e interpretarlo

```{r, message=FALSE, warning=FALSE}
variables <- c('Survived','Pclass','Sex','Age','Fare')

ggpairs(dataset.preproc[variables],
        mapping = aes(colour= Survived)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + theme_bw()
```

## 1.5. Mostrar la distribución de clase (Sobrevivientes vs No Sobrevivientes)

```{r}
ggplot(dataset.preproc, 
       aes(x=Survived, fill=Survived)) + 
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 50)) +
  labs(title = "Supervivencia - Distribución de clases",
       y = "Frecuencia absoluta") +
  scale_x_discrete("Supervivencia", breaks = c("0","1"),
                   labels=c("No sobrevivientes","Sobrevivientes")) +
  theme(legend.position = "none")

```

```{r}
# porcentaje de sobrevivientes
round((342 / nrow(dataset.preproc)) * 100,0)
```


## 1.6. Dividir al dataset en conjunto de entrenamiento (70% de los datos) y validación (30% de los datos). Volver a analizar la distribución de clase para chequear que este balanceado

Realizamos una partición entre dataset de entrenamiento (70%) y testeo (30%) usando la función resample_partition del paquete modelr

```{r}
train_valid <- dataset.preproc %>% resample_partition(c(train=0.7,valid=0.3))

trainsetM <- train_valid$train %>% as_tibble()
validationsetM <- train_valid$valid %>% as_tibble()

trainplotM <- ggplot(trainsetM, 
       aes(x=Survived, fill=Survived)) + 
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 50)) +
  labs(title = "Conjunto de entrenamiento",
       y = "Frecuencia absoluta") +
  scale_x_discrete("Supervivencia", breaks = c("0","1"),
                   labels=c("No sobrevivientes","Sobrevivientes")) +
  theme(legend.position = "none")

validplotM <- ggplot(validationsetM, 
       aes(x=Survived, fill=Survived)) + 
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 24)) +
  labs(title = "Conjunto de validación",
       y = "Frecuencia absoluta") +
  scale_x_discrete("Supervivencia", breaks = c("0","1"),
                   labels=c("No sobrevivientes","Sobrevivientes")) +
  theme(legend.position = "none")

grid.arrange(
  trainplotM,
  validplotM,
  nrow = 1,
  top = "Supervivencia - Distribución de clases - modelr"
)
```

```{r}
# porcentaje de sobrevivientes en set de entrenamiento
round((249 / nrow(trainsetM)) * 100,0)

# porcentaje de sobrevivientes en set de validación
round((93 / nrow(validationsetM)) * 100,0)
```

El conjunto de validación tiene 5% menos de sobrevivientes.

Se opta por utilizar la función createDataPartition de la librería caret.

```{r}
trainIndex <- createDataPartition(dataset.preproc$Survived, p = .7, 
                                  list = FALSE, 
                                  times = 1)

trainsetC <- dataset.preproc[ trainIndex,]
validationsetC  <- dataset.preproc[-trainIndex,]

trainplotC <- ggplot(trainsetC, 
       aes(x=Survived, fill=Survived)) + 
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 50)) +
  labs(title = "Conjunto de entrenamiento",
       y = "Frecuencia absoluta") +
  scale_x_discrete("Supervivencia", breaks = c("0","1"),
                   labels=c("No sobrevivientes","Sobrevivientes")) +
  theme(legend.position = "none")

validplotC <- ggplot(validationsetC, 
       aes(x=Survived, fill=Survived)) + 
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), position = position_fill(vjust = 22)) +
  labs(title = "Conjunto de validación",
       y = "Frecuencia absoluta") +
  scale_x_discrete("Supervivencia", breaks = c("0","1"),
                   labels=c("No sobrevivientes","Sobrevivientes")) +
  theme(legend.position = "none")

grid.arrange(
  trainplotC,
  validplotC,
  nrow = 1,
  top = "Supervivencia - Distribución de clases - caret"
)

```

```{r}
# porcentaje de sobrevivientes en set de entrenamiento
round((240 / nrow(trainsetC)) * 100,0)

# porcentaje de sobrevivientes en set de validación
round((102 / nrow(validationsetC)) * 100,0)
```

# 2. Predicciones

## 2.1. Realizar un modelo de regresión logística para predecir la supervivencia en función de Pclass, Sex y Age. Usar solo el dataset de entrenamiento

```{r}
glm.fit <- glm(Survived ~ Pclass + Sex + Age, data = trainsetC, family = "binomial")

summary(glm.fit)
```

## 2.2. Dar una breve interpretación de los coeficientes y su significatividad

TO-DO

## 2.3. ¿Quién tiene una mayor probabilidad de supervivencia? Rose que es una mujer de 17 años que viaja en primera clase o Jack que es un hombre de 20 años viajando en tercera clase

```{r}
rose <- data.frame(Pclass = as.factor(1), 
                   Sex = "female",
                   Age = 17)

rose.prob <- predict(object = glm.fit, newdata = rose, type = "response")

round(rose.prob,3)

jack <- data.frame(Pclass = as.factor(3),
                   Sex = "male",
                   Age = 20)

jack.prob <- predict(object = glm.fit, newdata = jack, type = "response")

round(jack.prob,3)
```

# 3. Generación de modelos

## 3.1. Generar 3 modelos de regresión logística sobre el dataset de entrenamiento utilizando diferentes combinaciones de variables. Al menos dos modelos deben ser multivariados

```{r}
logit_formulae <- formulas(.response = ~Survived,
                           model0 = ~ Pclass + Sex + Age,
                           model1 = ~ Pclass + Sex, 
                           model2 = ~ Pclass + Embarked + Sex + Age,
                           model3 = ~ Embarked + Sex
                         )

models <- data_frame(logit_formulae) %>% 
  mutate(models = names(logit_formulae), 
         expression = paste(logit_formulae), 
         mod = map(logit_formulae, ~glm(.,family = 'binomial', data = trainsetC))) 

models
```


```{r}
models %>% 
  filter(grepl('1|2|3', models)) %>% 
  mutate(tidy = map(mod,tidy)) %>%  
  unnest(tidy, .drop = TRUE) %>% 
  mutate(estimate=round(estimate,5),
         p.value=round(p.value,4))
```

TO-DO: analizar modelos

## 3.2. Ordenar por la deviance los 3 modelos creados en el punto 3)a) y el creado en el punto 2)a) y seleccionar el mejor modelo en términos de la deviance explicada

```{r}
models <- models %>% 
  mutate(glance = map(mod,glance))

models %>% 
  unnest(glance, .drop = TRUE) %>%
  mutate(perc_explained_dev = 1-(deviance/null.deviance)) %>% 
  select(-c(models, df.null, AIC, BIC)) %>% 
  arrange(deviance)
```

Mejor modelo: modelo2

# 4. Evaluación del 

## 4.1. Realizar el gráfico de curva ROC y obtener el AUC para el modelo elegido. Interpretar el gráfico

```{r}
models <- models %>% 
  mutate(pred= map(mod,augment, type.predict = "response"))

prediction <- models %>% 
  filter(grepl('2', models)) %>% 
  unnest(pred, .drop=TRUE)
 
roc_data <- roc(response=prediction$Survived, predictor=prediction$.fitted)

ggroc(roc_data, size=1, color="turquoise3") + 
  geom_abline(slope = 1, intercept = 1, linetype='dashed') +
  theme_bw() + 
  labs(title='Curva ROC', 
       subtitle = 'Modelo2: Survived ~ Pclass + Embarked + Sex + Age')

```

```{r}
print(paste('AUC: Modelo2: Survived~Pclass+Embarked+Sex+Age:', roc_data$auc))
```

## 4.2. Realizar un violin plot e interpretar

```{r}
ggplot(prediction, aes(x=Survived, y=.fitted, group=Survived,fill=factor(Survived))) + 
  geom_violin() +
  theme_bw() +
  guides(fill=FALSE) +
  scale_x_discrete("Supervivencia", breaks = c("0","1"),
                   labels=c("No sobrevivientes","Sobrevivientes")) +
  labs(title='Violin plot', 
       subtitle = 'Modelo2: Survived ~ Pclass + Embarked + Sex + Age', 
       y='Probabilidad predicha')
```


# 5. Elección del punto de corte

## 5.1. Sobre el dataset de validación realizar un gráfico de Accuracy, Specificity, Recall y Precision en función del punto de corte


```{r}
valid <- models %>% 
  filter(grepl('2',models)) %>% 
  mutate(val= map(mod,augment, newdata=validationsetC, type.predict = "response"))

valid.results <-  valid %>%
  unnest(val, .drop=TRUE)

valid.results
```


```{r}
prediction_metrics <- function(cutoff, predictions=valid.results){
  table <- predictions %>% 
    mutate(predicted_class=if_else(.fitted>cutoff, 1, 0) %>% as.factor(),
           Survived= factor(Survived))
  confusionMatrix(table(table$predicted_class, table$Survived), positive = "1") %>%
    tidy() %>%
    select(term, estimate) %>%
    filter(term %in% c('accuracy', 'sensitivity', 'specificity', 'precision','recall')) %>%
    mutate(cutoff=cutoff)
}

cutoffs = seq(0.05,0.95,0.01)
logit_pred= map_dfr(cutoffs, prediction_metrics) %>% mutate(term=as.factor(term))

ggplot(logit_pred, aes(cutoff,estimate, group=term, color=term)) + geom_line(size=1) +
  theme_bw() +
  labs(title= 'Accuracy, Sensitivity, Specificity, Recall y Precision', subtitle= 'Model2 - Sobre conjunto de validación', color="")
```


## 5.2. Elegir un punto de corte y explicar su decisión

0.4

## 5.3. Obtener la matriz de confusión con el modelo y punto de corte elegidos. Interpretarla

```{r}
sel_cutoff = 0.40

table <- valid.results %>% 
  mutate(predicted_class=if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(), 
         Survived = factor(Survived))

# Creamos la matriz de confusión
confusionMatrix(table(table$Survived, table$predicted_class), positive = "1")
```

# 6. Dataset de testeo